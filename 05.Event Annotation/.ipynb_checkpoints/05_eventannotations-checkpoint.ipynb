{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will transform some annotation data into a format useful for training a frame-based \"event detection\" or \"transcription\" system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 1: Using the variables given below, calculate (and store in a new variable) the time step in seconds, from one spectrogram frame to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate = 22050    # in Hertz (1/second)\n",
    "fftlength = 1024      # in samples (unitless)\n",
    "hop = 0.5             # a ratio (unitless)\n",
    "\n",
    "hop_len = hop * fftlength # hop length\n",
    "hop_size_s =hop_len / samplerate # hop length in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the CSV annotation data (code provided):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...first you will need to extract an annotation file. We've provided it, but it is in a Zip file. You'll need to unzip the CSV files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('pwd')\n",
    "# This will unzip the data into a folder NEXT TO wherever this notebook file is stored.\n",
    "\n",
    "#!unzip -n \"./temporal_annotations_nips4b.zip\"\n",
    "\n",
    "# The above should work on the jhub server.\n",
    "# If not on jhub server, you could download the dataset from:\n",
    "#      https://figshare.com/articles/Transcriptions_of_NIPS4B_2013_Bird_Challenge_Training_Dataset/6798548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data:\n",
      "{'start': 0.095782313, 'dur': 0.044988662, 'class': 'Unknown'}\n",
      "{'start': 0.220589569, 'dur': 0.243809524, 'class': 'Butbut_call'}\n",
      "{'start': 0.592108844, 'dur': 0.023219955, 'class': 'Erirub_call'}\n",
      "{'start': 0.825759637, 'dur': 0.026122449, 'class': 'Erirub_call'}\n",
      "{'start': 1.584761905, 'dur': 0.400544218, 'class': 'Butbut_call'}\n",
      "{'start': 2.265396825, 'dur': 0.02031746, 'class': 'Erirub_call'}\n",
      "{'start': 2.356825397, 'dur': 0.201723356, 'class': 'Parate_call'}\n",
      "{'start': 2.478730159, 'dur': 0.046439909, 'class': 'Erirub_call'}\n",
      "{'start': 3.601995465, 'dur': 0.236553288, 'class': 'Unknown'}\n"
     ]
    }
   ],
   "source": [
    "annotpath = \"temporal_annotations_nips4b/annotation_train001.csv\"\n",
    "\n",
    "import csv, numpy\n",
    "\n",
    "def processrow(arow):\n",
    "    \"This function takes a data row from text CSV, and converts data types\"\n",
    "    # the raw CSV format is starttime, duration, class\n",
    "    return {\n",
    "        'start': float(arow[0]),\n",
    "        'dur':   float(arow[1]),\n",
    "        'class': arow[2],\n",
    "    }\n",
    "\n",
    "# Now we do the actual loading, and process the CSV file line by line\n",
    "with open(annotpath, 'r') as infp:\n",
    "    rdr = csv.reader(infp)\n",
    "    annots = [processrow(row) for row in rdr]\n",
    "    \n",
    "#print(\"Some of the data:\")\n",
    "#for entry in annots[:5]:\n",
    "print(\"The data:\")\n",
    "for entry in annots:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the data:\n",
      "Butbut_call -> 4\n",
      "Erirub_call -> 22\n",
      "4 -> Butbut_call\n",
      "22 -> Erirub_call\n"
     ]
    }
   ],
   "source": [
    "# for convenience, this block is to load the list of classes from the CSV file and build 2 maps: classname --> classid and classid --> classname\n",
    "# you should view the file to see how it looks\n",
    "class_list_path = \"./nips4b_birdchallenge_espece_list.csv\"\n",
    "classname2id = {} # classname --> classid map\n",
    "id2classname = {} # classid --> classname map\n",
    "with open(class_list_path, 'r') as infp:\n",
    "    rdr = csv.reader(infp)\n",
    "    next(rdr, None)  # skip the headers\n",
    "    next(rdr, None)  # skip the first line with \"Empty\" class \n",
    "    for row in rdr:\n",
    "        classname2id[row[1]] = int(row[0]) # map class name to class id\n",
    "        id2classname[int(row[0])] = row[1] # map class id to class name\n",
    "classname2id[\"Unknown\"] = len(classname2id) # handle additional \"Unknown\" class\n",
    "id2classname[len(id2classname)] = \"Unknown\" # handle additional \"Unknown\" class\n",
    "\n",
    "print(\"Some of the data:\")\n",
    "print(\"Butbut_call\" + \" -> \" + str(classname2id[\"Butbut_call\"]))\n",
    "print(\"Erirub_call\" + \" -> \" + str(classname2id[\"Erirub_call\"]))\n",
    "print(\"4\" + \" -> \" + id2classname[4])\n",
    "print(\"22\" + \" -> \" + id2classname[22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 2: Now, using the time step variable that you calculated above, write some code that will take the annotation data and convert it into a numpy matrix of ones and zeros.\n",
    "\n",
    "The dimensions of the matrix should represent (#frame, #class) where #frame is the number of time frames and #class is the number of classes. The matrix should have a 1 where each class is active at that time frame and 0 where it is not.\n",
    "\n",
    "__Hints__: \n",
    "- The maximum length of an audio file is __5 seconds__, you should use this to calculate #frame.\n",
    "- Using the time step variable that you calculated in QUESTION 1 to calculate __frame rate__ (i.e. the number of frames in one second) from which a time in seconds can be converted to a time frame index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215, 88)\n",
      "{'start': 0.095782313, 'dur': 0.044988662, 'class': 'Unknown'}\n",
      "{'start': 0.220589569, 'dur': 0.243809524, 'class': 'Butbut_call'}\n",
      "{'start': 0.592108844, 'dur': 0.023219955, 'class': 'Erirub_call'}\n",
      "{'start': 0.825759637, 'dur': 0.026122449, 'class': 'Erirub_call'}\n",
      "{'start': 1.584761905, 'dur': 0.400544218, 'class': 'Butbut_call'}\n",
      "{'start': 2.265396825, 'dur': 0.02031746, 'class': 'Erirub_call'}\n",
      "{'start': 2.356825397, 'dur': 0.201723356, 'class': 'Parate_call'}\n",
      "{'start': 2.478730159, 'dur': 0.046439909, 'class': 'Erirub_call'}\n",
      "{'start': 3.601995465, 'dur': 0.236553288, 'class': 'Unknown'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x256ecacac40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUjElEQVR4nO3df7DddZ3f8efrJiFKEkgCGNMQG2SjDjprxPDDIq4ru1tkHNG2Q6Fbl10Zox2c1Y4zW3VnVredztjWH1unLU5cU7HDsiC/ZBy6/CpV1y66N4AQRAU0SGhIIAjhZ0hy3/3jfG85xHvJvfece8/Jl+dj5sz9ns/3/HjlnpNXvvmc7/l+U1VIktplZNABJEn9Z7lLUgtZ7pLUQpa7JLWQ5S5JLTR/0AEADsvCegWLBh1Dkg4pT/KrR6vqmInWDUW5v4JFnJIzBh1Dkg4pN9UVD0y2zmkZSWohy12SWshyl6QWstwlqYUsd0lqIctdklrIcpekFrLcJamFLHdJaiHLXZJa6KDlnmR1kluS/DjJ3Uk+1owvT3Jjknubn8ua8ST5cpL7ktyZ5MTZ/kNIkl5sKlvu+4BPVNUJwKnAhUlOAD4J3FxVa4Gbm+sA7wbWNpcNwEV9Ty1JekkHLfeq2l5VtzXLTwL3AKuAs4GLm5tdDLyvWT4b+EZ13AosTbKy38ElSZOb1px7kjXAW4AfACuqanuz6mFgRbO8Cniw627bmrEDH2tDktEko3vZM93ckqSXMOVyT7IYuBL4eFXt7l5XVQXUdJ64qjZW1fqqWr+AhdO5qyTpIKZU7kkW0Cn2S6rqqmZ4x/h0S/NzZzP+ELC66+7HNmOSpDkylb1lAnwNuKeqvti16lrg/Gb5fOBbXeN/0Ow1cyrwRNf0jSRpDkzlTEynAR8A7kpyRzP2aeBzwOVJLgAeAM5p1l0HnAXcBzwD/FE/A0uSDu6g5V5VfwtkktW/dm68Zv79wh5zSZJ64DdUJamFLHdJaiHLXZJayHKXpBay3CWphSx3SWohy12SWshyl6QWstwlqYUsd0lqIctdklrIcpekFrLcJamFLHdJaiHLXZJayHKXpBaaymn2NiXZmWRL19hlSe5oLlvHz9CUZE2SZ7vWfWUWs0uSJjGV0+x9HfgvwDfGB6rqn48vJ/kC8ETX7e+vqnV9yidJmoGpnGbvu0nWTLSuOXn2OcC7+pxLktSDXufcTwd2VNW9XWPHJbk9yXeSnD7ZHZNsSDKaZHQve3qMIUnqNpVpmZdyHnBp1/XtwGuqaleStwLXJHljVe0+8I5VtRHYCHBEllePOSRJXWa85Z5kPvBPgMvGx6pqT1XtapY3A/cDr+s1pCRpenqZlvkd4CdVtW18IMkxSeY1y68F1gI/7y2iJGm6prIr5KXA3wGvT7ItyQXNqnN58ZQMwDuAO5tdI68APlJVj/UxryRpCqayt8x5k4z/4QRjVwJX9h5LktQLv6EqSS1kuUtSC1nuktRClrsktVCvX2KSJM2BecuWUatWsPeYwxmbl87gjVdMenvLXZKG3cg8nj5tLY9d8BTXnPhljl+wGIB5K1/iLnMUTZI0hyx3SWohy12SWshyl6QWstwlqYUsd0lqIctdklrIcpekFrLcJamF/IaqJB0Csr947tnDuH/vMkb41cFvX/XS56ZOsgl4D7Czqt7UjH0W+BDwSHOzT1fVdc26TwEXAPuBP66q6w8W4ogsr1NyxkHDSpJecFNdsbmq1k+0birTMl8Hzpxg/EtVta65jBf7CXROv/fG5j7/bfycqpKkuXPQcq+q7wJTPQ/q2cBfV9WeqvoFcB9wcg/5JEkz0MsHqh9NcmeSTUmWNWOrgAe7brOtGZMkzaGZlvtFwPHAOmA78IXpPkCSDUlGk4zuZc8MY0iSJjKjcq+qHVW1v6rGgK/ywtTLQ8Dqrpse24xN9Bgbq2p9Va1fwMKZxJAkTWJG5Z6k+xDx7we2NMvXAucmWZjkOGAt8MPeIkqSpuug+7knuRR4J3B0km3AZ4B3JlkHFLAV+DBAVd2d5HLgx8A+4MKq2j8rySVJkzrofu5zwf3cJWn6et3PXZJ0iLHcJamFLHdJaiHLXZJayHKXpBay3CWphSx3SWohy12SWshyl6QWstwlqYUsd0lqIctdklrIcpekFrLcJamFLHdJaiHLXZJayHKXpBY6aLkn2ZRkZ5ItXWP/KclPktyZ5OokS5vxNUmeTXJHc/nKLGaXJE1iKlvuXwfOPGDsRuBNVfWbwM+AT3Wtu7+q1jWXj/QnpiRpOg5a7lX1XeCxA8ZuqKp9zdVbgWNnIZskaYb6Mef+QeB/dl0/LsntSb6T5PTJ7pRkQ5LRJKN72dOHGJKkcfN7uXOSPwX2AZc0Q9uB11TVriRvBa5J8saq2n3gfatqI7AR4Igsr15ySJJebMZb7kn+EHgP8PtVVQBVtaeqdjXLm4H7gdf1IackaRpmVO5JzgT+BHhvVT3TNX5MknnN8muBtcDP+xFUkjR1B52WSXIp8E7g6CTbgM/Q2TtmIXBjEoBbmz1j3gH82yR7gTHgI1X12IQPLEmaNQct96o6b4Lhr01y2yuBK3sNJUnqjd9QlaQWstwlqYUsd0lqIctdklrIcpekFrLcJamFLHdJaiHLXZJayHKXpBbq6aiQUpvMW7aMZ/7Rb/DwKfPZ8+p9zH9sPq+6rVj6va3s2/7woONJ0+KWu9TIEYvZeeIC/uX7buEX7/kqn33/5ew4BcaOWjroaNK0ueXeIiNLlvD8ya9jx0kLefbVYyx4YoSj79rPkd9/wC1P6WXGLfcWGTliCTtOWsj7zv0e95/zFT73L77B//0tGFuxfNDRJM0xt9xbpJ58imNuf56rFpzOJavexoLH5/HqO4qRRx5nbNDhJM0py71F9u/ezWHXj7L6+heP75v45pJazGkZSWqhKZV7kk1JdibZ0jW2PMmNSe5tfi5rxpPky0nuS3JnkhNnK7wkaWJT3XL/OnDmAWOfBG6uqrXAzc11gHfTOXfqWmADcFHvMSVJ0zGlOfeq+m6SNQcMn03n3KoAFwP/G/g3zfg3qqqAW5MsTbKyqrb3JbE0S+rpZ1j6szE2fe+3uPLYdTz+yGKOvjuMPPGUH0jrkNPLB6orugr7YWBFs7wKeLDrdtuasReVe5INdLbseQWH9xBD6o/9j+5iyWW7WHJZ5/qrmnE/kNahqC8fqDZb6TXN+2ysqvVVtX4BC/sRQ5LU6GXLfcf4dEuSlcDOZvwhYHXX7Y5txjTLsnAhI699DU8fv4w9S0eY/2yx+IGnGfnZL9m/e/eg40maQ71suV8LnN8snw98q2v8D5q9Zk4FnnC+fW6MLF7EYycexYPn7OPVH/oFuz+wm+2nHwGvOmrQ0STNsSltuSe5lM6Hp0cn2QZ8BvgccHmSC4AHgHOam18HnAXcBzwD/FGfM2sS+3c9xpGX3MqRl8CzwEp2dMYHG0vSAEx1b5nzJll1xgS3LeDCXkJJknrjN1QlqYUsd0lqIctdklrIcpekFrLcJamFLHdJaiHLXZJayHKXpBay3CWphQ7pc6hmwWGMHLGYvPKVkFDP7aGefJKx554bdDRJGqhDd8s9Yc8Zb+bnF63iS9+/nL/6u2/C5QvYde5bGDnc48NLenk7dMtdkjQpy12SWshyl6QWstwlqYUsd0lqoRnvCpnk9cBlXUOvBf4MWAp8CHikGf90VV030+eRJE3fjMu9qn4KrANIMo/OSbCvpnNavS9V1ef7EVCSNH39mpY5A7i/qh7o0+NJknrQr3I/F7i06/pHk9yZZFOSZRPdIcmGJKNJRveyp08xJEnQh3JPchjwXuCbzdBFwPF0pmy2A1+Y6H5VtbGq1lfV+gUs7DWGJKlLP7bc3w3cVlU7AKpqR1Xtr6ox4KvAyX14DknSNPSj3M+ja0omycqude8HtvThOSRJ09DTUSGTLAJ+F/hw1/B/TLIOKGDrAeskSXOgp3KvqqeBow4Y+0BPiSRJPfMbqpLUQpa7JLVQqmrQGTgiy+uUnDGzOyeQ5t+oGoMh+PNI0ly4qa7YXFXrJ1p3SJ9mD+iUee0fdApJGipOy0hSC1nuktRClrsktZDlLkktZLlLUgtZ7pLUQpa7JLWQ5S5JLWS5S1ILWe6S1EKWuyS1kOUuSS1kuUtSC/V8VMgkW4Engf3Avqpan2Q5cBmwhs6p9s6pql/1+lySpKnp15b7b1fVuq7jCn8SuLmq1gI3N9clSXNktqZlzgYubpYvBt43S88jSZpAP8q9gBuSbE6yoRlbUVXbm+WHgRUH3inJhiSjSUb3sqcPMSRJ4/pxJqa3V9VDSV4F3JjkJ90rq6qS/Nq576pqI7AROqfZ60MOSVKj5y33qnqo+bkTuBo4GdiRZCVA83Nnr88jSZq6nso9yaIkS8aXgd8DtgDXAuc3Nzsf+FYvzyNJmp5ep2VWAFcnGX+sv6qqv0ny98DlSS4AHgDO6fF5JEnT0FO5V9XPgTdPML4LOKOXx5YkzZzfUJWkFrLcJamFLHdJaiHLXZJayHKXpBay3CWphSx3SWohy12SWqgfBw7TkBhZsoTnT3odO05ayLMrxjhs9whH3bWfI//PA+zb/vCg40maQ265t0zND2PzoQ4rxhYUNS8w4sssvdy45d4iY08+yYIbRll9w4vH9w0mjqQBcpNOklrIcpekFrLcJamFLHdJaiHLXZJaaMblnmR1kluS/DjJ3Uk+1ox/NslDSe5oLmf1L64kaSp62RVyH/CJqrqtOY/q5iQ3Nuu+VFWf7z2eJGkmZlzuVbUd2N4sP5nkHmBVv4Jp+rJwISNrVvPM8cvYs3Qe858tFm19ipH7H2T/7t2DjidpDvVlzj3JGuAtwA+aoY8muTPJpiTLJrnPhiSjSUb3sqcfMV72RhYv4rGTjubB8/ax6l/dx+7zd7P9nUfCq44adDRJcyxV1dsDJIuB7wD/vqquSrICeBQo4N8BK6vqgy/1GEdkeZ0Sz6ctSdNxU12xuarWT7Supy33JAuAK4FLquoqgKraUVX7q2oM+Cpwci/PIUmavl72lgnwNeCeqvpi1/jKrpu9H9gy83iSpJnoZW+Z04APAHcluaMZ+zRwXpJ1dKZltgIf7uE5JEkz0MveMn8LZIJV1808jiSpHw7pQ/6OLFnCyDFHsX/5YkgY2f0s7NzF/scfhx4/KJakQ9mhW+4Jz532BrZ/8DmuPeUrrJg3wnn3/lMevfgNHHX5jxh75plBJ5SkgfHYMpLUQpa7JLWQ5S5JLWS5S1ILWe6S1EKWuyS1kOUuSS1kuUtSCx26X2ICMlbs2zufh/cvAp7mqecXkv2DTiVJg9fz8dz7weO5S9L0zdrx3CVJw+mQnpaRpJeNBDJC5s17Yez5yW9uuUvSsBuZx3NnvZXHLniKa07cyPELFgMwb+Xkd7HcJekQMTYWnq8R9tbB9xyZtQ9Uk5wJ/GdgHvCXVfW5yW7rB6qSNH1z/oFqknnAfwXeDZxA59R7J8zGc0mSft1s7S1zMnBfVf28qp4H/ho4e5aeS5J0gNkq91XAg13XtzVj/1+SDUlGk4zuZc8sxZCkl6eBfaBaVRuBjQBJHrmprngAOBp4dFCZXoK5psdc0zOsuWB4s5mr4x9OtmK2yv0hYHXX9WObsQlV1TEASUYn+3BgkMw1PeaanmHNBcObzVwHN1vTMn8PrE1yXJLDgHOBa2fpuSRJB5iVLfeq2pfko8D1dHaF3FRVd8/Gc0mSft2szblX1XXAddO828bZyNIH5poec03PsOaC4c1mroMYiqNCSpL6y6NCSlILWe6S1EJDU+5Jzkzy0yT3JfnkAHNsSrIzyZauseVJbkxyb/Nz2QByrU5yS5IfJ7k7yceGIVuSVyT5YZIfNbn+vBk/LskPmtfzsmavqTmXZF6S25N8e1hyJdma5K4kdyQZbcaG4T22NMkVSX6S5J4kbxt0riSvb35P45fdST4+6FxNtn/dvOe3JLm0+bsw8PfXuKEo9yE7Fs3XgTMPGPskcHNVrQVubq7PtX3AJ6rqBOBU4MLmdzTobHuAd1XVm4F1wJlJTgX+A/ClqvoN4FfABXOca9zHgHu6rg9Lrt+uqnVd+0QP+nWEzoH+/qaq3gC8mc7vbaC5quqnze9pHfBW4Bng6kHnSrIK+GNgfVW9ic5egecyPO8vqKqBX4C3Add3Xf8U8KkB5lkDbOm6/lNgZbO8EvjpEPzOvgX87jBlAw4HbgNOofMtvfkTvb5zmOdYOn/x3wV8G8iQ5NoKHH3A2EBfR+BI4Bc0O1kMS64Dsvwe8P1hyMULh1hZTmevw28D/3gY3l/jl6HYcmcKx6IZsBVVtb1ZfhhYMcgwSdYAbwF+wBBka6Y+7gB2AjcC9wOPV9W+5iaDej3/AvgTYKy5ftSQ5CrghiSbk2xoxgb9Oh4HPAL892Ya6y+TLBqCXN3OBS5tlgeaq6oeAj4P/BLYDjwBbGY43l/AkEzLHEqq80/ywPYfTbIYuBL4eFXt7l43qGxVtb86/20+ls4RQd8w1xkOlOQ9wM6q2jzoLBN4e1WdSGca8sIk7+heOaDXcT5wInBRVb0FeJoDpjoG+d5v5q7fC3zzwHWDyNXM8Z9N5x/FfwAs4tencwdqWMp9WseiGYAdSVYCND93DiJEkgV0iv2SqrpqmLIBVNXjwC10/ju6NMn4l+QG8XqeBrw3yVY6h5x+F5055UHnGt/qo6p20pk/PpnBv47bgG1V9YPm+hV0yn7Quca9G7itqnY01wed63eAX1TVI1W1F7iKzntu4O+vccNS7sN+LJprgfOb5fPpzHfPqSQBvgbcU1VfHJZsSY5JsrRZfiWdzwHuoVPy/2xQuarqU1V1bFWtofN++l9V9fuDzpVkUZIl48t05pG3MODXsaoeBh5M8vpm6Azgx4PO1eU8XpiSgcHn+iVwapLDm7+b47+vgb6/XmRQk/0TfEBxFvAzOvO1fzrAHJfSmUPbS2dr5gI6c7U3A/cCNwHLB5Dr7XT+63kncEdzOWvQ2YDfBG5vcm0B/qwZfy3wQ+A+Ov+VXjjA1/SdwLeHIVfz/D9qLnePv9cH/To2GdYBo81reQ2wbEhyLQJ2AUd2jQ1Drj8HftK87/8HsHDQ76/ui4cfkKQWGpZpGUlSH1nuktRClrsktZDlLkktZLlLUgtZ7pLUQpa7JLXQ/wPeL2R27qyjPAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "audio_max_len_samples = 5*samplerate # each audio file is 5 seconds\n",
    "max_frames = int(numpy.ceil((audio_max_len_samples - fftlength) / hop_len + 1)) # maximum number of frames per audio file\n",
    "num_classes = len(classname2id) # number of classes\n",
    "\n",
    "# frame_rate = 1/hop_size_s # frame rate 写法1\n",
    "frame_rate = max_frames / 5 # 写法2\n",
    "\n",
    "annotation_matrix = numpy.zeros((max_frames, num_classes))\n",
    "print(annotation_matrix.shape)\n",
    "for entry in annots: # iterate the annotation one by one\n",
    "    # COMPLETE YOUR CODE HERE\n",
    "    # start = int(numpy.ceil((entry['start'] * samplerate - fftlength) / hop_len + 1))\n",
    "    # end = int(numpy.ceil(((entry['start'] + entry['dur']) * samplerate - fftlength) / hop_len + 1))\n",
    "    start = int(frame_rate * entry['start'])\n",
    "    end = int(frame_rate * (entry['start'] + entry['dur']))\n",
    "    annotation_matrix[start:end, classname2id[entry['class']]] = 1\n",
    "    print(entry)\n",
    "# try to visualize annotation matrix\n",
    "plt.imshow(annotation_matrix,aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 3: Once you have done the above, write some code that does the opposite - i.e. converts an annotation matrix back into a list of events given with start time, end time and class label. (This is the kind of post-processing we might do with the *output* from an event detection system.)\n",
    "\n",
    "__Hints__: For each column (corresponding to one class), find the indices of non-zeros entries (you can use `numpy.where` function for this), then find chunks of continuous numbers in the list of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "Some of the data:\n",
      "{'class': 'Unknown', 'start_time': 0.09302325581395349, 'end_time': 0.11627906976744186}\n",
      "{'class': 'Butbut_call', 'start_time': 0.20930232558139536, 'end_time': 0.4186046511627907}\n",
      "{'class': 'Erirub_call', 'start_time': 0.5813953488372093, 'end_time': 0.813953488372093}\n",
      "{'class': 'Butbut_call', 'start_time': 1.5813953488372092, 'end_time': 1.9534883720930232}\n",
      "{'class': 'Erirub_call', 'start_time': 2.255813953488372, 'end_time': 2.255813953488372}\n",
      "{'class': 'Parate_call', 'start_time': 2.3488372093023258, 'end_time': 2.441860465116279}\n",
      "{'class': 'Erirub_call', 'start_time': 2.4651162790697674, 'end_time': 2.4651162790697674}\n",
      "{'class': 'Parate_call', 'start_time': 2.4651162790697674, 'end_time': 2.4651162790697674}\n",
      "{'class': 'Erirub_call', 'start_time': 2.488372093023256, 'end_time': 2.488372093023256}\n",
      "{'class': 'Parate_call', 'start_time': 2.488372093023256, 'end_time': 2.5348837209302326}\n",
      "{'class': 'Unknown', 'start_time': 3.5813953488372094, 'end_time': 3.813953488372093}\n"
     ]
    }
   ],
   "source": [
    "output_dict = list() # the list to store the annotation\n",
    "# COMPLETE YOUR CODE HERE\n",
    "index = numpy.where(annotation_matrix !=0)\n",
    "print(len(index[0]))\n",
    "lastClass = ''\n",
    "for i in range(len(index[0])):\n",
    "    currentClass = id2classname[index[1][i]]\n",
    "    time = index[0][i] / frame_rate\n",
    "    if currentClass != lastClass:\n",
    "        output_dict.append({'class':currentClass, 'start_time': time,  'end_time': time})\n",
    "    else:\n",
    "        output_dict[len(output_dict)-1].update({'end_time': time})\n",
    "    lastClass = currentClass\n",
    "\n",
    "print(\"Some of the data:\")\n",
    "for entry in output_dict:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QEUSTION 4: Compare the original annotations (as loaded) against the annotations produced when you apply your conversion followed by your back-conversion. Are there differences? Of what kind?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The order\n",
    "- Some differences in the time values due to rounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
